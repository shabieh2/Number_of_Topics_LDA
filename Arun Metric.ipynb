{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Finding the Natural Number of Topics with Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plotter\n",
    "import feather\n",
    "import multiprocessing\n",
    "\n",
    "from scipy import stats, linalg\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INFILE = r'.\\output\\notes_clean_compact.feather'\n",
    "INFILE_STOPWORDS = r'.\\data\\stopwords.csv'\n",
    "MINIMUM_TERM_N = 25 #if the word frequency is < N it is not used\n",
    "MAXIMUM_DOC_PROPORTION = 0.3 #if the word appears in more than x% of documents it is not used\n",
    "NUM_WORKERS = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compact = feather.read_dataframe(INFILE)\n",
    "documents = df_compact.notes_standard_transfrom.tolist()\n",
    "TOTAL_DOCUMENTS = len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove common words and tokenize\n",
    "stoplist = set(pd.read_csv(r'.\\data\\stopwords.csv').STOPWORDS_CUSTOM.tolist())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document pruning logic is implemented here. We only keep tokens that appear at a minimum `MINIMUM_TERM_N` times and are in not above `MAXIMUM_DOC_PROPORTION` percentage of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > MINIMUM_TERM_N]\n",
    "         for text in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_above=MAXIMUM_DOC_PROPORTION)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting documents to bag-of-words representation. We can hold everything in memory as it is a relatiely small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now define Arun et al metric. From the paper:\n",
    "\n",
    "We view LDA as a matrix factorization method which factorizes a document-word frequency matrix $M$ into two matrices $M1$ and $M2$ of order $T∗W$ and $D∗T$ respectively where $T$ is the number of topics and $W$ is the size of the vocabulary of the corpus. We propose a new measure that computes the symmetric Kullback-Leibler divergence of the Singluar value distributions of matrix $M1$ and the distribution of the vector $L∗M2$ where $L$ is a $1 ∗ D$ vector containing the lengths of each document in the corpus.\n",
    "\n",
    "$CM1$ - distribution of topics in the corpus $C$ got from the matrix $M1$\n",
    "\n",
    "$CM2$ - distribution over singular values of matrix $M1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arun(corpus, dictionary, max_topics, min_topics=1, step=1):\n",
    "    score = []\n",
    "    for i in range(min_topics,max_topics,step):\n",
    "        \n",
    "        #Fitting LDA model. Using multi-core for performance boost\n",
    "        lda = models.ldamulticore.LdaMulticore(corpus=corpus\n",
    "                                               ,id2word=dictionary\n",
    "                                               ,num_topics=i\n",
    "                                               ,workers=NUM_WORKERS)\n",
    "        \n",
    "        m1 = lda.expElogbeta # gives the topic-word distribution for each topic, i.e. p(word|topic)\n",
    "        u,cm1,v = np.linalg.svd(m1, full_matrices=False) #lets use this; fast and we do not use full matrix anyway\n",
    "        \n",
    "        #Document-topic matrix\n",
    "        lda_topics = lda[bmc_corpus]\n",
    "        m2 = matutils.corpus2dense(lda_topics, lda.num_topics, TOTAL_DOCUMENTS)\n",
    "        m2 = m2.transpose()\n",
    "        cm2 = l.dot(m2)\n",
    "        cm2 = cm2 + 0.0001\n",
    "        cm2norm = np.linalg.norm(l)\n",
    "        cm2 = cm2/cm2norm\n",
    "        \n",
    "        #Calculate divergence measure\n",
    "        score_iteration = sym_kl(cm1,cm2)\n",
    "        \n",
    "        #Append score for this run\n",
    "        score.append(score_iteration)\n",
    "        \n",
    "        print('Finished running topic {0:3d}; Divergence measure:{1:.3f}'.format(i, score_iteration))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the symmetric KL divergence function\n",
    "$ProposedMeasure(M1,M2) = KL(CM1||CM2) + KL(CM2||CM1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define symmetric KL divergence function\n",
    "def sym_kl(p,q):\n",
    "    return np.sum([stats.entropy(p,q),stats.entropy(q,p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need the $L$ vector which, as mentioned above, is a vector containing the lengths of each document in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = np.array([sum(cnt for _, cnt in doc) for doc in bmc_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running topic   1; Divergence measure:0.000\n"
     ]
    }
   ],
   "source": [
    "%lprun -f arun arun(bmc_corpus,dictionary,max_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fitting LDA model. Using multi-core for performance boost\n",
    "lda = models.ldamulticore.LdaMulticore(corpus=bmc_corpus\n",
    "                                       ,id2word=dictionary\n",
    "                                       ,num_topics=2\n",
    "                                       ,workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.35267299,  0.9405632 ,  0.95922583, ...,  0.90538317,\n",
       "         0.40841088,  0.10225472],\n",
       "       [ 0.64732701,  0.05943678,  0.04077417, ...,  0.09461683,\n",
       "         0.59158915,  0.89774531]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time matutils.corpus2dense(lda[bmc_corpus], lda.num_topics, TOTAL_DOCUMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.35269361,  0.94057698,  0.95922504, ...,  0.90539204,\n",
       "          0.40837986,  0.10225515],\n",
       "        [ 0.64730639,  0.05942302,  0.04077496, ...,  0.09460796,\n",
       "          0.59162014,  0.89774485]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time matutils.corpus2csc(lda[bmc_corpus], num_terms=lda.num_topics, num_docs=TOTAL_DOCUMENTS).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8980854e645c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'kl' is not defined"
     ]
    }
   ],
   "source": [
    "kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot kl divergence against number of topics\n",
    "plt.plot(kl)\n",
    "plt.ylabel('Symmetric KL Divergence')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.savefig('kldiv.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
